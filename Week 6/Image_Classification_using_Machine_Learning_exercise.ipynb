{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeozLGFv922L"
      },
      "source": [
        "# Image Classification using Logistic Regression and Softmax Regression\n",
        "### Fashion-MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-7TRSa8922M"
      },
      "source": [
        "## 1. Install Required Libraries\n",
        "Before starting, you need to install the necessary Python libraries:\n",
        "- **TensorFlow**: Used for building and training the Softmax Regression model.\n",
        "- **Scikit-Learn**: Provides the Logistic Regression implementation.\n",
        "- **Matplotlib**: Used for plotting images and confusion matrices.\n",
        "```bash\n",
        "pip install tensorflow scikit-learn matplotlib\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnF5bCMY922M"
      },
      "source": [
        "## 2. Import Necessary Libraries\n",
        "In this step, we import the necessary libraries to handle data processing, model training, and evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B-Sa3Ku7922M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix , f1_score\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfLJPfVC922N"
      },
      "source": [
        "## 3. Load and Preprocess the Fashion-MNIST Dataset\n",
        "Fashion-MNIST is a dataset of Zalando's article images consisting of 60,000 training images and 10,000 test images, categorized into 10 classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP4zaGye922N",
        "outputId": "04e3f6fd-32a7-4ce6-f10d-5271048b92ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X train flatten (60000, 784)\n",
            "X test flatten (10000, 784)\n"
          ]
        }
      ],
      "source": [
        "# Load the Fashion-MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Flatten images for Logistic Regression\n",
        "train_images_flat = train_images.reshape(60000, -1)\n",
        "test_images_flat = test_images.reshape(10000, -1)\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "print(\"X train flatten\",train_images_flat.shape)\n",
        "print(\"X test flatten\",test_images_flat.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHQ5xeeR922N"
      },
      "source": [
        "## 4. Logistic Regression for Image Classification\n",
        "Logistic Regression is used for multi-class classification. We fit the model using the flattened images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVGwXX8U922N",
        "outputId": "91cb21c7-f702-427d-837b-7af274ede790"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 84.39%\n",
            "F1 Score: 84.31%\n",
            "Confusion Matrix:\n",
            "[[807   4  17  48   5   2 108   0   9   0]\n",
            " [  2 961   1  25   5   0   4   0   2   0]\n",
            " [ 19   6 735  12 131   1  86   0  10   0]\n",
            " [ 30  12  12 869  29   0  44   0   4   0]\n",
            " [  0   2 108  38 756   1  87   0   8   0]\n",
            " [  0   0   0   1   0 925   0  51   3  20]\n",
            " [129   2 129  40 106   1 568   0  25   0]\n",
            " [  0   0   0   0   0  33   0 938   0  29]\n",
            " [  7   1   6  10   3   5  21   5 942   0]\n",
            " [  0   0   0   0   0  13   0  47   2 938]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "model.fit(train_images_flat, np.argmax(train_labels, axis=1))\n",
        "\n",
        "y_pred = model.predict(test_images_flat)\n",
        "\n",
        "accuracy = accuracy_score(np.argmax(test_labels, axis=1), y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "f1 = f1_score(np.argmax(test_labels, axis=1), y_pred, average='weighted')\n",
        "print(f'F1 Score: {f1 * 100:.2f}%')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(np.argmax(test_labels, axis=1), y_pred)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glBceUlF922O"
      },
      "source": [
        "## 5. Softmax Regression (Using TensorFlow/Keras)\n",
        "Softmax Regression is implemented using a simple neural network in TensorFlow/Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD35mDDw922O",
        "outputId": "c79c9dc5-419b-41c0-ba27-78efdc4ff15f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7178 - loss: 0.8404 - val_accuracy: 0.8281 - val_loss: 0.5015\n",
            "Epoch 2/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8352 - loss: 0.4826 - val_accuracy: 0.8457 - val_loss: 0.4545\n",
            "Epoch 3/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8509 - loss: 0.4370 - val_accuracy: 0.8397 - val_loss: 0.4607\n",
            "Epoch 4/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8505 - loss: 0.4305 - val_accuracy: 0.8537 - val_loss: 0.4274\n",
            "Epoch 5/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8526 - loss: 0.4238 - val_accuracy: 0.8478 - val_loss: 0.4332\n",
            "Epoch 6/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8586 - loss: 0.4081 - val_accuracy: 0.8541 - val_loss: 0.4176\n",
            "Epoch 7/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8609 - loss: 0.4025 - val_accuracy: 0.8433 - val_loss: 0.4428\n",
            "Epoch 8/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8601 - loss: 0.4026 - val_accuracy: 0.8549 - val_loss: 0.4221\n",
            "Epoch 9/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8612 - loss: 0.3996 - val_accuracy: 0.8568 - val_loss: 0.4192\n",
            "Epoch 10/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8618 - loss: 0.3991 - val_accuracy: 0.8494 - val_loss: 0.4358\n",
            "Epoch 11/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8649 - loss: 0.3914 - val_accuracy: 0.8576 - val_loss: 0.4144\n",
            "Epoch 12/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8636 - loss: 0.3854 - val_accuracy: 0.8511 - val_loss: 0.4323\n",
            "Epoch 13/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8643 - loss: 0.3895 - val_accuracy: 0.8564 - val_loss: 0.4119\n",
            "Epoch 14/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8645 - loss: 0.3882 - val_accuracy: 0.8542 - val_loss: 0.4223\n",
            "Epoch 15/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8660 - loss: 0.3815 - val_accuracy: 0.8520 - val_loss: 0.4217\n",
            "Epoch 16/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8686 - loss: 0.3770 - val_accuracy: 0.8539 - val_loss: 0.4272\n",
            "Epoch 17/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8682 - loss: 0.3792 - val_accuracy: 0.8572 - val_loss: 0.4117\n",
            "Epoch 18/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8713 - loss: 0.3761 - val_accuracy: 0.8547 - val_loss: 0.4159\n",
            "Epoch 19/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8678 - loss: 0.3810 - val_accuracy: 0.8546 - val_loss: 0.4213\n",
            "Epoch 20/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8675 - loss: 0.3745 - val_accuracy: 0.8502 - val_loss: 0.4276\n",
            "Epoch 21/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8708 - loss: 0.3688 - val_accuracy: 0.8539 - val_loss: 0.4217\n",
            "Epoch 22/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8692 - loss: 0.3707 - val_accuracy: 0.8578 - val_loss: 0.4172\n",
            "Epoch 23/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8680 - loss: 0.3688 - val_accuracy: 0.8465 - val_loss: 0.4427\n",
            "Epoch 24/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8710 - loss: 0.3661 - val_accuracy: 0.8585 - val_loss: 0.4173\n",
            "Epoch 25/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8701 - loss: 0.3722 - val_accuracy: 0.8537 - val_loss: 0.4210\n",
            "Epoch 26/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8696 - loss: 0.3703 - val_accuracy: 0.8546 - val_loss: 0.4211\n",
            "Epoch 27/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8711 - loss: 0.3663 - val_accuracy: 0.8537 - val_loss: 0.4259\n",
            "Epoch 28/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8692 - loss: 0.3665 - val_accuracy: 0.8573 - val_loss: 0.4161\n",
            "Epoch 29/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8730 - loss: 0.3605 - val_accuracy: 0.8546 - val_loss: 0.4231\n",
            "Epoch 30/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8729 - loss: 0.3616 - val_accuracy: 0.8497 - val_loss: 0.4452\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e4e1931fc40>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "model2 = models.Sequential()\n",
        "model2.add(layers.Flatten(input_shape=(28, 28)))\n",
        "model2.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model2.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model2.fit(train_images, train_labels, epochs=30, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZFlONc9y1xIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3995874-1e2b-4ae1-e641-7da1e59c3631"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8419 - loss: 0.4616\n",
            "Test accuracy: 83.84%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model2.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVfYMhgQ922O"
      },
      "source": [
        "## 6. Visualize Model Predictions\n",
        "We visualize the predictions made by the Softmax Regression model on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5dVrUaxb922O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "a237c966-2759-4e8f-d049-81cc48704eb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize Model Predictions\n",
        "predictions = model2.predict(test_images)\n",
        "num_images_to_visualize = 5\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(num_images_to_visualize):\n",
        "  plt.subplot(1, num_images_to_visualize, i + 1)\n",
        "  plt.imshow(test_images[i], cmap='gray')\n",
        "  plt.title(f'Predicted: {np.argmax(predictions[i])}')\n",
        "  plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6xJKktw922O"
      },
      "source": [
        "### Summary\n",
        "- **Logistic Regression**: You flattened the images and used `LogisticRegression` from Scikit-Learn to classify the Fashion-MNIST dataset.\n",
        "- **Softmax Regression**: You used TensorFlow/Keras to build a simple neural network with a softmax activation function to classify the same dataset."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}